{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using this template**\n",
    "\n",
    "1. Change notebook title to assignment title you working on, eg. `Graded Challenge 1 or Milestone 1`\n",
    "2. Put your identity such as name and batch number below notebook title.\n",
    "3. Write your description before do any work. State your purpose of this assignment and what you are trying to achieve. \n",
    "4. Look at the rubric of this assignment and make sure you understand the criteria.\n",
    "5. Code your solution in the cell provided below the working area section.\n",
    "6. State your conlusions, findings, and any other relevant information in the cell provided below the conclusions sections.\n",
    "7. Save this notebook and rename it to assignment title you working on  eg. `Graded Challenge 1 or Milestone 1`\n",
    "8. Push your assignment before deadline.\n",
    "9. Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Challenge 2\n",
    "\n",
    "1. Name: Jason Rich Darmawan Onggo Putra\n",
    "2. Batch: 016 RMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Objective\n",
    "\n",
    "Analysis of the waste management and disposal system in the city of Austin. The analysis result will be the condition of the waste management and disposal system. In addition, the prediction of the weight of waste in the city of Austin on July 10, 2021.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "#### Problems 1\n",
    "\n",
    "- [ ] What is the average **time between delivery** of every dropoff site? \n",
    "= [ ] What is the **maximum** waste weight collected of every dropoff site **per day**?\n",
    "- [ ] What is the **average** waste weight collected of every dropoff site **per delivery**?\n",
    "- [ ] What is the **median** waste weight collected of every dropoff site **per delivery**?\n",
    "- [ ] What is the **mode** waste weight of every dropoff site **per delivery**?\n",
    "\n",
    "### Problems 2\n",
    "\n",
    "- [ ] What is the **maximum** waste weight collected of every dropoff site in July 10, 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Area\n",
    "\n",
    "```txt\n",
    "Put your code, analysis, everything below this line\n",
    "\n",
    "Make sure to check everything the rubric requires before you submit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieve\n",
    "\n",
    "1. project: `bigquery-public-data`\n",
    "2. dataset: [austin_waste](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&page=dataset&_ga=2.245085957.1471931019.1642739417-486643658.1638156099&project=lexical-period-361812&ws=!1m4!1m3!3m2!1sbigquery-public-data!2saustin_waste)\n",
    "3. table: [waste_and_diversion](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&page=dataset&_ga=2.245085957.1471931019.1642739417-486643658.1638156099&project=lexical-period-361812&ws=!1m5!1m4!4m3!1sbigquery-public-data!2saustin_waste!3swaste_and_diversion)\n",
    "\n",
    "**The query**:\n",
    "```\n",
    "SELECT report_date, load_time, load_type, load_weight, dropoff_site \n",
    "FROM `bigquery-public-data.austin_waste.waste_and_diversion`\n",
    "WHERE report_date BETWEEN '2021-01-01' AND '2021-07-09';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Issues:\n",
    "- [ ] column `report_date` dtype is `object`.\n",
    "- [ ] column `load_time` dtype is `object`.\n",
    "- [ ] column `load_weight` have `NaN` rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26157 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   26157 non-null  object \n",
      " 1   load_time     26157 non-null  object \n",
      " 2   load_type     26157 non-null  object \n",
      " 3   load_weight   25109 non-null  float64\n",
      " 4   dropoff_site  26157 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1021.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./h8dsft_P0GC2_jason_rich_darmawan_onggo_putra.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 12:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 11:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 03:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>800.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>2021-05-01 12:29:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>760.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2021-07-03 12:09:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date                load_time load_type  load_weight dropoff_site\n",
       "0  2021-07-08  2021-07-08 12:00:00 UTC     TIRES       2260.0          MRF\n",
       "1  2021-07-08  2021-07-08 11:00:00 UTC     TIRES       1260.0          MRF\n",
       "2  2021-07-08  2021-07-08 03:00:00 UTC     TIRES        800.0          MRF\n",
       "3  2021-05-01  2021-05-01 12:29:00 UTC     TIRES        760.0          MRF\n",
       "4  2021-07-03  2021-07-03 12:09:00 UTC     TIRES       1400.0          MRF"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:26:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26153</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:27:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 05:55:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26155</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-02 01:10:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26156</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 10:22:00 UTC</td>\n",
       "      <td>RECYCLED METAL</td>\n",
       "      <td>360.0</td>\n",
       "      <td>AUSTIN IRON AND METAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time       load_type  load_weight  \\\n",
       "26152  2021-03-01  2021-03-01 11:26:00 UTC        ORGANICS      12100.0   \n",
       "26153  2021-03-01  2021-03-01 04:27:00 UTC        ORGANICS      10900.0   \n",
       "26154  2021-03-01  2021-03-01 05:55:00 UTC        ORGANICS      21800.0   \n",
       "26155  2021-03-01  2021-03-02 01:10:00 UTC        ORGANICS       5640.0   \n",
       "26156  2021-03-01  2021-03-01 10:22:00 UTC  RECYCLED METAL        360.0   \n",
       "\n",
       "                dropoff_site  \n",
       "26152       ORGANICS BY GOSH  \n",
       "26153       ORGANICS BY GOSH  \n",
       "26154       ORGANICS BY GOSH  \n",
       "26155       ORGANICS BY GOSH  \n",
       "26156  AUSTIN IRON AND METAL  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find dropoff_site that have never filled the `load_weight` column this year\n",
    "\n",
    "dropoff_site that have never filled the `load_weight` column this year:\n",
    "- [x] `ONION CREEK`\n",
    "- [x] `PARK CENTER`\n",
    "- [x] `ST. EDWARDS`\n",
    "- [x] `WILCAB`\n",
    "\n",
    "The decision is to drop these rows because the analyst does not have previous data (of each dropoff_site) to fill the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_site</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUSTIN IRON AND METAL</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUSTIN WOOD RECYCLING</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES RECYCLING</th>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES WOODS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREAT NORTHERN</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORNSBY BEND</th>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRF</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON ROUTE HIGH DUMP</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONION CREEK</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS BY GOSH</th>\n",
       "      <td>5741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK BEND</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK CENTER</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST. EDWARDS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STEINER LANDFILL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS - MRF</th>\n",
       "      <td>2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS LANDFILL</th>\n",
       "      <td>10691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFIELD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILCAB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load_weight\n",
       "dropoff_site                      \n",
       "AUSTIN IRON AND METAL           50\n",
       "AUSTIN WOOD RECYCLING            2\n",
       "BALCONES RECYCLING            3837\n",
       "BALCONES WOODS                   1\n",
       "GREAT NORTHERN                   6\n",
       "HORNSBY BEND                  1652\n",
       "MRF                            168\n",
       "ON ROUTE HIGH DUMP               7\n",
       "ONION CREEK                      0\n",
       "ORGANICS BY GOSH              5741\n",
       "PARK BEND                        4\n",
       "PARK CENTER                      0\n",
       "ST. EDWARDS                      0\n",
       "STEINER LANDFILL                 1\n",
       "TDS - MRF                     2948\n",
       "TDS LANDFILL                 10691\n",
       "WESTFIELD                        1\n",
       "WILCAB                           0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['dropoff_site','load_weight']].groupby(['dropoff_site']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONION CREEK have at least once filled the `load_weight` column: False\n",
      "PARK CENTER have at least once filled the `load_weight` column: False\n",
      "ST. EDWARDS have at least once filled the `load_weight` column: False\n",
      "WILCAB have at least once filled the `load_weight` column: False\n"
     ]
    }
   ],
   "source": [
    "for dropoff_site in ['ONION CREEK', 'PARK CENTER', 'ST. EDWARDS', 'WILCAB']:\n",
    "    print(\"{0} have at least once filled the `load_weight` column: {1}\"\n",
    "            .format(dropoff_site, df.loc[df['dropoff_site'] == dropoff_site, 'load_weight'].notna().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25267 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   25267 non-null  object \n",
      " 1   load_time     25267 non-null  object \n",
      " 2   load_type     25267 non-null  object \n",
      " 3   load_weight   25109 non-null  float64\n",
      " 4   dropoff_site  25267 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.loc[-df['dropoff_site'].str.contains('ONION CREEK|PARK CENTER|ST. EDWARDS|WILCAB')].copy()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the dropoff_site that have NaN rows.\n",
    "\n",
    "- [ ] GREAT NORTHERN have 64 NaN rows\n",
    "- [ ] HORNSBY BEND have 3 NaN rows\n",
    "- [ ] ON ROUTE HIGH DUMP have 74 NaN rows\n",
    "- [ ] ORGANICS BY GOSH have 14 NaN rows\n",
    "- [ ] TDS LANDFILL have 3 NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropoff_site\n",
       "AUSTIN IRON AND METAL     0\n",
       "AUSTIN WOOD RECYCLING     0\n",
       "BALCONES RECYCLING        0\n",
       "BALCONES WOODS            0\n",
       "GREAT NORTHERN           64\n",
       "HORNSBY BEND              3\n",
       "MRF                       0\n",
       "ON ROUTE HIGH DUMP       74\n",
       "ORGANICS BY GOSH         14\n",
       "PARK BEND                 0\n",
       "STEINER LANDFILL          0\n",
       "TDS - MRF                 0\n",
       "TDS LANDFILL              3\n",
       "WESTFIELD                 0\n",
       "Name: load_weight, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[:,'load_weight'].isnull().groupby(df2['dropoff_site']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix: dropoff_site TDS LANDFILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>2021-06-11 08:45:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22528</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>2021-01-27 01:45:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>2021-02-12 01:07:00 UTC</td>\n",
       "      <td>GARBAGE COLLECTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time            load_type  load_weight  \\\n",
       "15818  2021-06-11  2021-06-11 08:45:00 UTC             SWEEPING          NaN   \n",
       "22528  2021-01-27  2021-01-27 01:45:00 UTC             SWEEPING          NaN   \n",
       "24540  2021-02-12  2021-02-12 01:07:00 UTC  GARBAGE COLLECTIONS          NaN   \n",
       "\n",
       "       dropoff_site  \n",
       "15818  TDS LANDFILL  \n",
       "22528  TDS LANDFILL  \n",
       "24540  TDS LANDFILL  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL = df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL')].copy()\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_weight'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix: dropoff_site TDS LANDFILL; load_type SWEEPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skew value for `load_type` == `SWEEPING` is 0.18. The conclusion is the data distribution is normal. Therefore, the decision is:\n",
    "1. Find the outliers with `mean +- 3 * std`. Then, take a decision to remove or keep the outliers.\n",
    "2. Then, fill the NaN rows with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18290906329280904"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING = df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'SWEEPING')]\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9097.925130423664, 18195.850260847328)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].std()\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].std()\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN + 3 * df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN - 3 * df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT, df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers found. We will decide whether those outliers are natural variations or a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2021-03-02 05:18:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18820.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>2021-05-06 03:14:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>21300.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11021</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>2021-05-06 08:52:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>20620.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11419</th>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>2021-05-10 11:56:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19180.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>2021-05-18 01:49:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15412</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>2021-06-09 12:52:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18260.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-07-06 01:43:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19880.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19026</th>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>2021-07-07 12:29:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18800.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25517</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-02-25 01:33:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19760.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "1225   2021-03-02  2021-03-02 05:18:00 UTC  SWEEPING      18820.0   \n",
       "11020  2021-05-06  2021-05-06 03:14:00 UTC  SWEEPING      21300.0   \n",
       "11021  2021-05-06  2021-05-06 08:52:00 UTC  SWEEPING      20620.0   \n",
       "11419  2021-05-10  2021-05-10 11:56:00 UTC  SWEEPING      19180.0   \n",
       "12600  2021-05-18  2021-05-18 01:49:00 UTC  SWEEPING      22760.0   \n",
       "15412  2021-06-09  2021-06-09 12:52:00 UTC  SWEEPING      18260.0   \n",
       "18897  2021-07-06  2021-07-06 01:43:00 UTC  SWEEPING      19880.0   \n",
       "19026  2021-07-07  2021-07-07 12:29:00 UTC  SWEEPING      18800.0   \n",
       "25517  2021-02-25  2021-02-25 01:33:00 UTC  SWEEPING      19760.0   \n",
       "\n",
       "       dropoff_site  \n",
       "1225   TDS LANDFILL  \n",
       "11020  TDS LANDFILL  \n",
       "11021  TDS LANDFILL  \n",
       "11419  TDS LANDFILL  \n",
       "12600  TDS LANDFILL  \n",
       "15412  TDS LANDFILL  \n",
       "18897  TDS LANDFILL  \n",
       "19026  TDS LANDFILL  \n",
       "25517  TDS LANDFILL  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT) \n",
    "                                           | (df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the outliers are natural variations. So, we will not remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11260.0    4\n",
       "8440.0     3\n",
       "7380.0     3\n",
       "14900.0    3\n",
       "8280.0     3\n",
       "Name: load_weight, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'SWEEPING') & (df3['load_weight'].isna()), 'load_weight'] = \\\n",
    "    df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'SWEEPING'), 'load_weight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>2021-02-12 01:07:00 UTC</td>\n",
       "      <td>GARBAGE COLLECTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time            load_type  load_weight  \\\n",
       "24540  2021-02-12  2021-02-12 01:07:00 UTC  GARBAGE COLLECTIONS          NaN   \n",
       "\n",
       "       dropoff_site  \n",
       "24540  TDS LANDFILL  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_weight'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix: dropoff_site TDS LANDFILL; load_type GARBAGE COLLECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skew value for `load_type` == `GARBAGE COLLECTIONS` is 5.56. The conclusion is the data distribution is skewed positively. Therefore, the decision are:\n",
    "\n",
    "1. Handle the outlier first with Inter-Quartile Range. Then, make the decision to remove or keep the outlierrs.\n",
    "2. If the skew is STILL above 0,5 or below -0,5. We will fill the NaN rows with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.564210731462809"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS = df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'GARBAGE COLLECTIONS')]\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4495.0, 39625.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3, df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1 = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,'load_weight'].quantile([.75,.25])\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3 - df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3 + df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR * 1.5\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1 - df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR * 1.5\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT, df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers found. We will decide whether those outliers are natural variations or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8204 entries, 565 to 26109\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   8204 non-null   object \n",
      " 1   load_time     8204 non-null   object \n",
      " 2   load_type     8204 non-null   object \n",
      " 3   load_weight   8203 non-null   float64\n",
      " 4   dropoff_site  8204 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 384.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "                                                      | (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)]\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS') & (df3['load_weight'] == 145160)]\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the outliers are NOT natural variations. So, we will remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_weight\n",
       "21780.0        18\n",
       "25900.0        17\n",
       "19480.0        16\n",
       "19120.0        16\n",
       "24600.0        15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,['load_weight']].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [report_date, load_time, load_type, load_weight, dropoff_site]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "New knowledge: drop with `DataFrame.drop()`, do not try to replace the value, otherwise you will be left with all NaN rows.\n",
    "\"\"\"\n",
    "# df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')] = \\\n",
    "#     df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "#                                                           & (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)\n",
    "#                                                           | (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'].isna())]\n",
    "df3 = df3.drop(df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL')\n",
    "                        & (df3['load_type'] == 'GARBAGE COLLECTIONS')\n",
    "                        & ( (df3['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) | (df3['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT) )\n",
    "                        & (df3['load_weight'].notna())]\n",
    "                  .index)\n",
    "\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')] \\\n",
    "   .loc[(df3['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "        | (df3['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the outliers, the skew changed to **-0.19**. We canconclude the data distribution is NOW normal. Therefore, we will replace the NaN rows with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19170335304750802"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS'), 'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS') & (df3['load_weight'].isna()), 'load_weight'] = \\\n",
    "    df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS'), 'load_weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will automate the process **Handle Outliers**\n",
    "\n",
    "It took way too long to preprocess one dropoff_site. Therefore, we will streamline the process.\n",
    "\n",
    "pseudo code:\n",
    "```\n",
    "def getSkew(dropoff_site: str, load_type: str) -> float: ...\n",
    "\n",
    "def getMedian(dropoff_site: str, load_type: str) -> float: ...\n",
    "\n",
    "class STRATEGY(Enum):\n",
    "    STANDARD_DEVIATION = 0\n",
    "    IQR = 1\n",
    "\n",
    "def getUpperLowerLimit(dropoff_site: str, load_type: str, strategy: STRATEGY) -> tuple[float, float]: ...\n",
    "\n",
    "for dropoff_site in dropoff_sites:\n",
    "    for load_type in load_types[dropoff_site]:\n",
    "        load_type_skew = getSkew(dropoff_site, load_type)\n",
    "        if (load_type_skew < -0.5) | (load_type_skew > 0.5):\n",
    "            lower_limit, upper_limit = getUpperLowerLimit(dropoff_site, load_type, strategy=STRATEGY.IQR)\n",
    "            df3 = df3.drop(df3[(df3['dropoff_site'] == dropoff_site) \n",
    "                               & (df3['load_type'] == load_type) \n",
    "                               & ( (df3['load_weight'] < lower_limit ) | ( df3['load_weight'] > upper_limit ) )\n",
    "                              ].index)\n",
    "        else:\n",
    "            print(\"dropoff_site {0} load_type {1} have normal data distribution\".format(dropoff_site, load_type))\n",
    "            pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some dropoff_site and load_type that still have skewed data distribution after the outliers treament:\n",
    "\n",
    "dropoff_site:\n",
    "- **MRF**, with load type:\n",
    "  - [ ] **TIRES**\n",
    "- **TDS LANDFILL**, with load type:\n",
    "  - [ ] **DEAD ANIMAL**\n",
    "  - [ ] **MIXED LITTER**\n",
    "  - [ ] **TIRES**\n",
    "  - [ ] **RECYCLING - SINGLE STREAM**\n",
    "- **ORGANICS BY GOSH**, with load type:\n",
    "  - [ ] **DEAD ANIMAL**\n",
    "- **ON ROUTE HIGH DUMP**, with load type:\n",
    "  - [ ] **ORGANICS**\n",
    "- **PARK BEND**, with load type:\n",
    "  - [ ] **ORGANICS**\n",
    "\n",
    "TODO: ask Instructor on how to handle skewed data distribution after the first outliers treatment failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping outliers in dropoff_site MRF load_type TIRES still have skewed value: 5.68 -> 0.56\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type DEAD ANIMAL still have skewed value: 2.25 -> 0.99\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type MIXED LITTER still have skewed value: 1.14 -> 0.63\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type TIRES still have skewed value: 3.09 -> -0.92\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type RECYCLING - SINGLE STREAM still have skewed value: 0.99 -> 0.99\n",
      "after dropping outliers in dropoff_site ORGANICS BY GOSH load_type DEAD ANIMAL still have skewed value: 3.49 -> 1.47\n",
      "after dropping outliers in dropoff_site ON ROUTE HIGH DUMP load_type ORGANICS still have skewed value: -0.88 -> -0.88\n",
      "after dropping outliers in dropoff_site PARK BEND load_type ORGANICS still have skewed value: 0.54 -> 0.54\n"
     ]
    }
   ],
   "source": [
    "class DEBUG_STRATEGY(Enum):\n",
    "    INFO = 0\n",
    "    VERBOSE = 1\n",
    "\n",
    "DEBUG = DEBUG_STRATEGY.INFO\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "def getSkew(dropoff_site: str, load_type: str) -> np.float64:\n",
    "    return df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                   & (df4['load_type'] == load_type), 'load_weight'] \\\n",
    "              .skew()\n",
    "\n",
    "class OUTLIER_STRATEGY(Enum):\n",
    "    IQR = 0\n",
    "\n",
    "def getLowerUpperLimit(dropoff_site: str, load_type: str, strategy: OUTLIER_STRATEGY) -> tuple[float, float]:\n",
    "    if strategy == OUTLIER_STRATEGY.IQR:\n",
    "        Q1, Q3 = df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                         & (df4['load_type'] == load_type), 'load_weight'] \\\n",
    "                    .quantile([.25, .75])\n",
    "        IQR = Q3 - Q1\n",
    "        return Q1 - IQR * 1.5, Q3 + IQR * 1.5\n",
    "    else:\n",
    "        raise NotImplementedError(\"currently just handle skewed data distribution\")\n",
    "\n",
    "getSkew('TDS LANDFILL', 'GARBAGE COLLECTIONS')\n",
    "getLowerUpperLimit('TDS LANDFILL', 'GARBAGE COLLECTIONS', OUTLIER_STRATEGY.IQR)\n",
    "\n",
    "for dropoff_site in df4.loc[:,'dropoff_site'].unique():\n",
    "    for load_type in df4.loc[df4['dropoff_site'] == dropoff_site, 'load_type'].unique():\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site=dropoff_site, load_type=load_type)\n",
    "        if np.isnan(dropoff_site_load_type_skew):\n",
    "            \"\"\"\n",
    "            load_type_skew with nan value can happen because: there is not enough data, like only 2 rows.\n",
    "            \"\"\"\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropping dropoff_site {0} load_type {1} because have nan skew value\".format(dropoff_site, load_type))\n",
    "            df4 = df4.drop(df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                                   & (df4['load_type'] == load_type)]\n",
    "                              .index)\n",
    "        elif (dropoff_site_load_type_skew < -0.5) | (dropoff_site_load_type_skew > 0.5):\n",
    "            lower_limit, upper_limit = getLowerUpperLimit(dropoff_site=dropoff_site, load_type=load_type, strategy=OUTLIER_STRATEGY.IQR)\n",
    "            df4 = df4.drop(df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                                   & (df4['load_type'] == load_type)\n",
    "                                   & ( (df4['load_weight'] < lower_limit) | (df4['load_weight'] > upper_limit) )]\n",
    "                              .index)\n",
    "            new_dropoff_site_load_type_skew = df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_type'] == load_type), 'load_weight'].skew()\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropping outliers in dropoff_site {0} load_type {1} because have skewed value: {2:.2f} -> {3:.2f}\".format(dropoff_site, load_type, dropoff_site_load_type_skew, new_dropoff_site_load_type_skew))\n",
    "            if (DEBUG == DEBUG_STRATEGY.INFO) & ((new_dropoff_site_load_type_skew < -0.5) | (new_dropoff_site_load_type_skew > 0.5)):\n",
    "                print(\"after dropping outliers in dropoff_site {0} load_type {1} still have skewed value: {2:.2f} -> {3:.2f}\".format(dropoff_site, load_type, dropoff_site_load_type_skew, new_dropoff_site_load_type_skew))\n",
    "        else:\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropoff_site {0} load_type {1} have skew value {2:.2f}. The decision is not to drop the outliers\".format(dropoff_site, load_type, dropoff_site_load_type_skew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN rows.\n",
    "\n",
    "Assuming we have done the outliers treatment.\n",
    "\n",
    "~~pseudo code:~~ we only identify 2 combinations, not worth to automate ┗(｀O ´)┛\n",
    "```\n",
    "for dropoff_site in dropoff_sites:\n",
    "    for load_type in dropoff_site['load_type']:\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site, load_type)\n",
    "        if (dropoff_site_load_type_skew < -0.5) | (dropoff_site_load_type_skew > 0.5):\n",
    "            # replace NaN with median\n",
    "        elif:\n",
    "            # repplace NaN with mean\n",
    "```\n",
    "\n",
    "We identified 2 combinations that have NaN rows and have normal data distribution:\n",
    "- [ ] dropoff_site HORNSBY BEND, load type BRUSH\n",
    "- [ ] dropoff_site ORGANICS BY GOSH, load type ORGANICS\n",
    "\n",
    "These combinations are not empty NaN rows. So we will replace it with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_site HORNSBY BEND load_type BRUSH skew 0.2636609436413962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:57:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 08:23:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:11:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 10:41:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>5680.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:21:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26005</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:25:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26006</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:32:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>8180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 01:31:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26008</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 02:40:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6680.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26009</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:01:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>5460.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "160    2021-03-20  2021-03-20 07:57:00 UTC     BRUSH       3800.0   \n",
       "161    2021-03-20  2021-03-20 08:23:00 UTC     BRUSH       4180.0   \n",
       "162    2021-03-20  2021-03-20 07:11:00 UTC     BRUSH       6500.0   \n",
       "163    2021-03-20  2021-03-20 10:41:00 UTC     BRUSH       5680.0   \n",
       "164    2021-03-20  2021-03-20 07:21:00 UTC     BRUSH       3180.0   \n",
       "...           ...                      ...       ...          ...   \n",
       "26005  2021-03-01  2021-03-01 04:25:00 UTC     BRUSH       6020.0   \n",
       "26006  2021-03-01  2021-03-01 11:32:00 UTC     BRUSH       8180.0   \n",
       "26007  2021-03-01  2021-03-01 01:31:00 UTC     BRUSH       2940.0   \n",
       "26008  2021-03-01  2021-03-01 02:40:00 UTC     BRUSH       6680.0   \n",
       "26009  2021-03-01  2021-03-01 04:01:00 UTC     BRUSH       5460.0   \n",
       "\n",
       "       dropoff_site  \n",
       "160    HORNSBY BEND  \n",
       "161    HORNSBY BEND  \n",
       "162    HORNSBY BEND  \n",
       "163    HORNSBY BEND  \n",
       "164    HORNSBY BEND  \n",
       "...             ...  \n",
       "26005  HORNSBY BEND  \n",
       "26006  HORNSBY BEND  \n",
       "26007  HORNSBY BEND  \n",
       "26008  HORNSBY BEND  \n",
       "26009  HORNSBY BEND  \n",
       "\n",
       "[1515 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_site ORGANICS BY GOSH load_type ORGANICS skew 0.07768898474656169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>2021-02-21 10:41:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>2021-03-14 01:37:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21700.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2021-03-21</td>\n",
       "      <td>2021-03-21 07:56:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>7120.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>2021-02-21 11:07:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>2021-03-14 03:04:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>20460.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26151</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:19:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>18580.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:26:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26153</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:27:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 05:55:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26155</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-02 01:10:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "775    2021-02-21  2021-02-21 10:41:00 UTC  ORGANICS       2480.0   \n",
       "776    2021-03-14  2021-03-14 01:37:00 UTC  ORGANICS      21700.0   \n",
       "777    2021-03-21  2021-03-21 07:56:00 UTC  ORGANICS       7120.0   \n",
       "778    2021-02-21  2021-02-21 11:07:00 UTC  ORGANICS       5560.0   \n",
       "779    2021-03-14  2021-03-14 03:04:00 UTC  ORGANICS      20460.0   \n",
       "...           ...                      ...       ...          ...   \n",
       "26151  2021-03-01  2021-03-01 11:19:00 UTC  ORGANICS      18580.0   \n",
       "26152  2021-03-01  2021-03-01 11:26:00 UTC  ORGANICS      12100.0   \n",
       "26153  2021-03-01  2021-03-01 04:27:00 UTC  ORGANICS      10900.0   \n",
       "26154  2021-03-01  2021-03-01 05:55:00 UTC  ORGANICS      21800.0   \n",
       "26155  2021-03-01  2021-03-02 01:10:00 UTC  ORGANICS       5640.0   \n",
       "\n",
       "           dropoff_site  \n",
       "775    ORGANICS BY GOSH  \n",
       "776    ORGANICS BY GOSH  \n",
       "777    ORGANICS BY GOSH  \n",
       "778    ORGANICS BY GOSH  \n",
       "779    ORGANICS BY GOSH  \n",
       "...                 ...  \n",
       "26151  ORGANICS BY GOSH  \n",
       "26152  ORGANICS BY GOSH  \n",
       "26153  ORGANICS BY GOSH  \n",
       "26154  ORGANICS BY GOSH  \n",
       "26155  ORGANICS BY GOSH  \n",
       "\n",
       "[5728 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dropoff_site in df4.loc[df4['load_weight'].isna(),'dropoff_site'].unique():\n",
    "    for load_type in df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_weight'].isna()), 'load_type'].unique():\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site=dropoff_site, load_type=load_type)\n",
    "        print(f\"dropoff_site {dropoff_site} load_type {load_type} skew {dropoff_site_load_type_skew}\")\n",
    "        display(df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_type'] == load_type)])\n",
    "\n",
    "df5 = df4.copy()\n",
    "\n",
    "df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "        & (df5['load_type'] == 'BRUSH') \n",
    "        & (df5['load_weight'].isna()), 'load_weight'] = df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "                                                                & (df5['load_type'] == 'BRUSH'), 'load_weight'] \\\n",
    "                                                            .mean()\n",
    "\n",
    "df5.loc[(df5['dropoff_site'] == 'ORGANICS BY GOSH') \n",
    "        & (df5['load_type'] == 'ORGANICS') \n",
    "        & (df5['load_weight'].isna()), 'load_weight'] = df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "                                                                & (df5['load_type'] == 'BRUSH'), 'load_weight'] \\\n",
    "                                                            .mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [report_date, load_time, load_type, load_weight, dropoff_site]\n",
       "Index: []"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions, Assumptions, Overall Analysis\n",
    "\n",
    "`put your conclusions here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "2. eksplorasi data\n",
    "a. rentang waktu pengambilan data\n",
    "b. tipe load sampah\n",
    "```\n",
    "df.loc[:,'load_type'].unique()\n",
    "```\n",
    "c. tempat pembuangan sampah\n",
    "```\n",
    "df.loc[:,'dropoff_site'].unique()\n",
    "```\n",
    "\n",
    "3. insight/infromasi untuk masing-masing site.\n",
    "```\n",
    "df.loc[df['dropoff_site'] == 'MRF'].groupby(['dropoff_site'])['load_weight'].agg([pd.Series.mean, pd.Series.median, pd.Series.mode])\n",
    "```\n",
    "\n",
    "4. site paling menarik + alasan\n",
    "\n",
    "5. site tersebut: column `load_weight` ada outlier? berapa persen? bandingkan mean, median, mode setelah datanya dibersihkan.\n",
    "\n",
    "6. site tersebut: range, variance, standar deviasi column `load_weight`\n",
    "\n",
    "pg_df_MRF = df.loc[df['dropoff_site'] == 'MRF','load_weight']\n",
    "pg_df_MRF.max() - pg_df_MRF.min()\n",
    "pg_df_MRF.var()\n",
    "pg_df_MRF.std() # np.sqrt(pandas.Series.var())\n",
    "\n",
    "7. menambah site baru: berapa kapasitas penampungan di site baru berdasarkan perhitungan confidence interval.\n",
    "\n",
    "8. uji hipotesis\n",
    "\n",
    "1. teknik handling outlier\n",
    "\n",
    "2. konsep dibaling confidence interval\n",
    "\n",
    "3. uji hipotesis\n",
    "\n",
    "### Problem 2\n",
    "\n",
    "forecasting.\n",
    "\n",
    "v = Δw / Δt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'load_type'].unique()\n",
    "df.loc[:,'dropoff_site'].unique()\n",
    "# force pandas to suppress the scientific notation\n",
    "# pd.options.display.float_format = '{:,.2f}'.format\n",
    "df.loc[df['dropoff_site'] == 'MRF'].groupby(['dropoff_site'])['load_weight'].agg([pd.Series.mean, pd.Series.median, pd.Series.mode])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
