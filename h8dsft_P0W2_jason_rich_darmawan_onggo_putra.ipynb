{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using this template**\n",
    "\n",
    "1. Change notebook title to assignment title you working on, eg. `Graded Challenge 1 or Milestone 1`\n",
    "2. Put your identity such as name and batch number below notebook title.\n",
    "3. Write your description before do any work. State your purpose of this assignment and what you are trying to achieve. \n",
    "4. Look at the rubric of this assignment and make sure you understand the criteria.\n",
    "5. Code your solution in the cell provided below the working area section.\n",
    "6. State your conlusions, findings, and any other relevant information in the cell provided below the conclusions sections.\n",
    "7. Save this notebook and rename it to assignment title you working on  eg. `Graded Challenge 1 or Milestone 1`\n",
    "8. Push your assignment before deadline.\n",
    "9. Good Luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Challenge 2\n",
    "\n",
    "1. Name: Jason Rich Darmawan Onggo Putra\n",
    "2. Batch: 016 RMT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "### Objective\n",
    "\n",
    "Analysis of the waste management and disposal system in the city of Austin. The analysis result will be the condition of the waste management and disposal system. In addition, the prediction of the weight of waste in the city of Austin on July 10, 2021.\n",
    "\n",
    "### Problem Statement\n",
    "\n",
    "#### Problems 1\n",
    "\n",
    "- [x] What is the average **time between delivery** of every dropoff site? [drop off site AUSTIN IRON AND METAL average load time between delivery is 3 days and 22 hours](#new-drop-off-site).\n",
    "- [x] What is the **average** waste weight collected of every dropoff site **per delivery**? [answer](#central-tendency)\n",
    "- [x] What is the **median** waste weight collected of every dropoff site **per delivery**? [answer](#central-tendency)\n",
    "- [x] What is the **mode** waste weight of every dropoff site **per delivery**? [answer](#central-tendency)\n",
    "\n",
    "### Problems 2\n",
    "\n",
    "- [ ] What is the **maximum** waste weight collected of every dropoff site in July 10, 2021?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Retrieve\n",
    "\n",
    "1. project: `bigquery-public-data`\n",
    "2. dataset: [austin_waste](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&page=dataset&_ga=2.245085957.1471931019.1642739417-486643658.1638156099&project=lexical-period-361812&ws=!1m4!1m3!3m2!1sbigquery-public-data!2saustin_waste)\n",
    "3. table: [waste_and_diversion](https://console.cloud.google.com/bigquery?p=bigquery-public-data&d=samples&page=dataset&_ga=2.245085957.1471931019.1642739417-486643658.1638156099&project=lexical-period-361812&ws=!1m5!1m4!4m3!1sbigquery-public-data!2saustin_waste!3swaste_and_diversion)\n",
    "\n",
    "**The query**:\n",
    "```\n",
    "SELECT report_date, load_time, load_type, load_weight, dropoff_site \n",
    "FROM `bigquery-public-data.austin_waste.waste_and_diversion`\n",
    "WHERE report_date BETWEEN '2021-01-01' AND '2021-07-09';\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from scipy import stats\n",
    "import sympy as sy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Issues:\n",
    "- [x] column `report_date` dtype is `object`. [Fix](#change-column-report_date-and-load_time-dtype)\n",
    "- [x] column `load_time` dtype is `object`. [Fix](#change-column-report_date-and-load_time-dtype)\n",
    "- [x] column `load_weight` have `NaN` rows. [Fix](#data-preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26157 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   26157 non-null  object \n",
      " 1   load_time     26157 non-null  object \n",
      " 2   load_type     26157 non-null  object \n",
      " 3   load_weight   25109 non-null  float64\n",
      " 4   dropoff_site  26157 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1021.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./h8dsft_P0GC2_jason_rich_darmawan_onggo_putra.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 12:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>2260.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 11:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-08</td>\n",
       "      <td>2021-07-08 03:00:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>800.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>2021-05-01 12:29:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>760.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-03</td>\n",
       "      <td>2021-07-03 12:09:00 UTC</td>\n",
       "      <td>TIRES</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>MRF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date                load_time load_type  load_weight dropoff_site\n",
       "0  2021-07-08  2021-07-08 12:00:00 UTC     TIRES       2260.0          MRF\n",
       "1  2021-07-08  2021-07-08 11:00:00 UTC     TIRES       1260.0          MRF\n",
       "2  2021-07-08  2021-07-08 03:00:00 UTC     TIRES        800.0          MRF\n",
       "3  2021-05-01  2021-05-01 12:29:00 UTC     TIRES        760.0          MRF\n",
       "4  2021-07-03  2021-07-03 12:09:00 UTC     TIRES       1400.0          MRF"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:26:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26153</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:27:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 05:55:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26155</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-02 01:10:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26156</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 10:22:00 UTC</td>\n",
       "      <td>RECYCLED METAL</td>\n",
       "      <td>360.0</td>\n",
       "      <td>AUSTIN IRON AND METAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time       load_type  load_weight  \\\n",
       "26152  2021-03-01  2021-03-01 11:26:00 UTC        ORGANICS      12100.0   \n",
       "26153  2021-03-01  2021-03-01 04:27:00 UTC        ORGANICS      10900.0   \n",
       "26154  2021-03-01  2021-03-01 05:55:00 UTC        ORGANICS      21800.0   \n",
       "26155  2021-03-01  2021-03-02 01:10:00 UTC        ORGANICS       5640.0   \n",
       "26156  2021-03-01  2021-03-01 10:22:00 UTC  RECYCLED METAL        360.0   \n",
       "\n",
       "                dropoff_site  \n",
       "26152       ORGANICS BY GOSH  \n",
       "26153       ORGANICS BY GOSH  \n",
       "26154       ORGANICS BY GOSH  \n",
       "26155       ORGANICS BY GOSH  \n",
       "26156  AUSTIN IRON AND METAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find dropoff_site that have never filled the `load_weight` column this year\n",
    "\n",
    "dropoff_site that have never filled the `load_weight` column this year:\n",
    "- [x] `ONION CREEK`\n",
    "- [x] `PARK CENTER`\n",
    "- [x] `ST. EDWARDS`\n",
    "- [x] `WILCAB`\n",
    "\n",
    "The decision is to drop these rows because the analyst does not have previous data (of each dropoff_site) to fill the missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>load_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_site</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUSTIN IRON AND METAL</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUSTIN WOOD RECYCLING</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES RECYCLING</th>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES WOODS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREAT NORTHERN</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORNSBY BEND</th>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRF</th>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON ROUTE HIGH DUMP</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ONION CREEK</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS BY GOSH</th>\n",
       "      <td>5741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK BEND</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK CENTER</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ST. EDWARDS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STEINER LANDFILL</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS - MRF</th>\n",
       "      <td>2948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS LANDFILL</th>\n",
       "      <td>10691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFIELD</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WILCAB</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       load_weight\n",
       "dropoff_site                      \n",
       "AUSTIN IRON AND METAL           50\n",
       "AUSTIN WOOD RECYCLING            2\n",
       "BALCONES RECYCLING            3837\n",
       "BALCONES WOODS                   1\n",
       "GREAT NORTHERN                   6\n",
       "HORNSBY BEND                  1652\n",
       "MRF                            168\n",
       "ON ROUTE HIGH DUMP               7\n",
       "ONION CREEK                      0\n",
       "ORGANICS BY GOSH              5741\n",
       "PARK BEND                        4\n",
       "PARK CENTER                      0\n",
       "ST. EDWARDS                      0\n",
       "STEINER LANDFILL                 1\n",
       "TDS - MRF                     2948\n",
       "TDS LANDFILL                 10691\n",
       "WESTFIELD                        1\n",
       "WILCAB                           0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,['dropoff_site','load_weight']].groupby(['dropoff_site']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONION CREEK have at least once filled the `load_weight` column: False\n",
      "PARK CENTER have at least once filled the `load_weight` column: False\n",
      "ST. EDWARDS have at least once filled the `load_weight` column: False\n",
      "WILCAB have at least once filled the `load_weight` column: False\n"
     ]
    }
   ],
   "source": [
    "for dropoff_site in ['ONION CREEK', 'PARK CENTER', 'ST. EDWARDS', 'WILCAB']:\n",
    "    print(\"{0} have at least once filled the `load_weight` column: {1}\"\n",
    "            .format(dropoff_site, df.loc[df['dropoff_site'] == dropoff_site, 'load_weight'].notna().any()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25267 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   25267 non-null  object \n",
      " 1   load_time     25267 non-null  object \n",
      " 2   load_type     25267 non-null  object \n",
      " 3   load_weight   25109 non-null  float64\n",
      " 4   dropoff_site  25267 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df2 = df.loc[-df['dropoff_site'].str.contains('ONION CREEK|PARK CENTER|ST. EDWARDS|WILCAB')].copy()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the dropoff_site that have NaN rows.\n",
    "\n",
    "- [ ] GREAT NORTHERN have 64 NaN rows\n",
    "- [ ] HORNSBY BEND have 3 NaN rows\n",
    "- [ ] ON ROUTE HIGH DUMP have 74 NaN rows\n",
    "- [ ] ORGANICS BY GOSH have 14 NaN rows\n",
    "- [ ] TDS LANDFILL have 3 NaN rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dropoff_site\n",
       "AUSTIN IRON AND METAL     0\n",
       "AUSTIN WOOD RECYCLING     0\n",
       "BALCONES RECYCLING        0\n",
       "BALCONES WOODS            0\n",
       "GREAT NORTHERN           64\n",
       "HORNSBY BEND              3\n",
       "MRF                       0\n",
       "ON ROUTE HIGH DUMP       74\n",
       "ORGANICS BY GOSH         14\n",
       "PARK BEND                 0\n",
       "STEINER LANDFILL          0\n",
       "TDS - MRF                 0\n",
       "TDS LANDFILL              3\n",
       "WESTFIELD                 0\n",
       "Name: load_weight, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc[:,'load_weight'].isnull().groupby(df2['dropoff_site']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fix: dropoff_site TDS LANDFILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>2021-06-11</td>\n",
       "      <td>2021-06-11 08:45:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22528</th>\n",
       "      <td>2021-01-27</td>\n",
       "      <td>2021-01-27 01:45:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>2021-02-12 01:07:00 UTC</td>\n",
       "      <td>GARBAGE COLLECTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time            load_type  load_weight  \\\n",
       "15818  2021-06-11  2021-06-11 08:45:00 UTC             SWEEPING          NaN   \n",
       "22528  2021-01-27  2021-01-27 01:45:00 UTC             SWEEPING          NaN   \n",
       "24540  2021-02-12  2021-02-12 01:07:00 UTC  GARBAGE COLLECTIONS          NaN   \n",
       "\n",
       "       dropoff_site  \n",
       "15818  TDS LANDFILL  \n",
       "22528  TDS LANDFILL  \n",
       "24540  TDS LANDFILL  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL = df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL')].copy()\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_weight'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix: dropoff_site TDS LANDFILL; load_type SWEEPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skew value for `load_type` == `SWEEPING` is 0.18. The conclusion is the data distribution is normal. Therefore, the decision is:\n",
    "1. Find the outliers with `mean +- 3 * std`. Then, take a decision to remove or keep the outliers.\n",
    "2. Then, fill the NaN rows with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18290906329280904"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING = df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'SWEEPING')]\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-9097.925130423664, 18195.850260847328)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].std()\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].std()\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN + 3 * df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_MEAN - 3 * df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_STD\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT, df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers found. We will decide whether those outliers are natural variations or a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>2021-03-02 05:18:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18820.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11020</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>2021-05-06 03:14:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>21300.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11021</th>\n",
       "      <td>2021-05-06</td>\n",
       "      <td>2021-05-06 08:52:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>20620.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11419</th>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>2021-05-10 11:56:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19180.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12600</th>\n",
       "      <td>2021-05-18</td>\n",
       "      <td>2021-05-18 01:49:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15412</th>\n",
       "      <td>2021-06-09</td>\n",
       "      <td>2021-06-09 12:52:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18260.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18897</th>\n",
       "      <td>2021-07-06</td>\n",
       "      <td>2021-07-06 01:43:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19880.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19026</th>\n",
       "      <td>2021-07-07</td>\n",
       "      <td>2021-07-07 12:29:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>18800.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25517</th>\n",
       "      <td>2021-02-25</td>\n",
       "      <td>2021-02-25 01:33:00 UTC</td>\n",
       "      <td>SWEEPING</td>\n",
       "      <td>19760.0</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "1225   2021-03-02  2021-03-02 05:18:00 UTC  SWEEPING      18820.0   \n",
       "11020  2021-05-06  2021-05-06 03:14:00 UTC  SWEEPING      21300.0   \n",
       "11021  2021-05-06  2021-05-06 08:52:00 UTC  SWEEPING      20620.0   \n",
       "11419  2021-05-10  2021-05-10 11:56:00 UTC  SWEEPING      19180.0   \n",
       "12600  2021-05-18  2021-05-18 01:49:00 UTC  SWEEPING      22760.0   \n",
       "15412  2021-06-09  2021-06-09 12:52:00 UTC  SWEEPING      18260.0   \n",
       "18897  2021-07-06  2021-07-06 01:43:00 UTC  SWEEPING      19880.0   \n",
       "19026  2021-07-07  2021-07-07 12:29:00 UTC  SWEEPING      18800.0   \n",
       "25517  2021-02-25  2021-02-25 01:33:00 UTC  SWEEPING      19760.0   \n",
       "\n",
       "       dropoff_site  \n",
       "1225   TDS LANDFILL  \n",
       "11020  TDS LANDFILL  \n",
       "11021  TDS LANDFILL  \n",
       "11419  TDS LANDFILL  \n",
       "12600  TDS LANDFILL  \n",
       "15412  TDS LANDFILL  \n",
       "18897  TDS LANDFILL  \n",
       "19026  TDS LANDFILL  \n",
       "25517  TDS LANDFILL  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_LOWER_LIMIT) \n",
    "                                           | (df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING_UPPER_LIMIT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the outliers are natural variations. So, we will not remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11260.0    4\n",
       "8440.0     3\n",
       "7380.0     3\n",
       "14900.0    3\n",
       "8280.0     3\n",
       "Name: load_weight, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_SWEEPING.loc[:,'load_weight'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'SWEEPING') & (df3['load_weight'].isna()), 'load_weight'] = \\\n",
    "    df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'SWEEPING'), 'load_weight'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24540</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>2021-02-12 01:07:00 UTC</td>\n",
       "      <td>GARBAGE COLLECTIONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TDS LANDFILL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time            load_type  load_weight  \\\n",
       "24540  2021-02-12  2021-02-12 01:07:00 UTC  GARBAGE COLLECTIONS          NaN   \n",
       "\n",
       "       dropoff_site  \n",
       "24540  TDS LANDFILL  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_weight'].isna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fix: dropoff_site TDS LANDFILL; load_type GARBAGE COLLECTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skew value for `load_type` == `GARBAGE COLLECTIONS` is 5.56. The conclusion is the data distribution is skewed positively. Therefore, the decision are:\n",
    "\n",
    "1. Handle the outlier first with Inter-Quartile Range. Then, make the decision to remove or keep the outlierrs.\n",
    "2. If the skew is STILL above 0,5 or below -0,5. We will fill the NaN rows with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.564210731462809"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS = df3_DROPOFF_SITE_TDS_LANDFILL.loc[(df3_DROPOFF_SITE_TDS_LANDFILL['load_type'] == 'GARBAGE COLLECTIONS')]\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4495.0, 39625.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3, df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1 = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,'load_weight'].quantile([.75,.25])\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3 - df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q3 + df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR * 1.5\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT = df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_Q1 - df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_IQR * 1.5\n",
    "\n",
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT, df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some outliers found. We will decide whether those outliers are natural variations or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8204 entries, 565 to 26109\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   8204 non-null   object \n",
      " 1   load_time     8204 non-null   object \n",
      " 2   load_type     8204 non-null   object \n",
      " 3   load_weight   8203 non-null   float64\n",
      " 4   dropoff_site  8204 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 384.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "                                                      | (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)]\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS') & (df3['load_weight'] == 145160)]\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that the outliers are NOT natural variations. So, we will remove the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_weight\n",
       "21780.0        18\n",
       "25900.0        17\n",
       "19480.0        16\n",
       "19120.0        16\n",
       "24600.0        15\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[:,['load_weight']].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [report_date, load_time, load_type, load_weight, dropoff_site]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "New knowledge: drop with `DataFrame.drop()`, do not try to replace the value, otherwise you will be left with all NaN rows.\n",
    "\"\"\"\n",
    "# df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')] = \\\n",
    "#     df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS.loc[(df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "#                                                           & (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)\n",
    "#                                                           | (df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS['load_weight'].isna())]\n",
    "df3 = df3.drop(df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL')\n",
    "                        & (df3['load_type'] == 'GARBAGE COLLECTIONS')\n",
    "                        & ( (df3['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) | (df3['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT) )\n",
    "                        & (df3['load_weight'].notna())]\n",
    "                  .index)\n",
    "\n",
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS')] \\\n",
    "   .loc[(df3['load_weight'] < df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_LOWER_LIMIT) \n",
    "        | (df3['load_weight'] > df3_DROPOFF_SITE_TDS_LANDFILL_GARBAGE_COLLECTIONS_UPPER_LIMIT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the outliers, the skew changed to **-0.19**. We canconclude the data distribution is NOW normal. Therefore, we will replace the NaN rows with the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.19170335304750802"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS'), 'load_weight'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS') & (df3['load_weight'].isna()), 'load_weight'] = \\\n",
    "    df3.loc[(df3['dropoff_site'] == 'TDS LANDFILL') & (df3['load_type'] == 'GARBAGE COLLECTIONS'), 'load_weight'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will automate the process **Handle Outliers**\n",
    "\n",
    "It took way too long to preprocess one dropoff_site. Therefore, we will streamline the process.\n",
    "\n",
    "pseudo code:\n",
    "```\n",
    "def getSkew(dropoff_site: str, load_type: str) -> float: ...\n",
    "\n",
    "def getMedian(dropoff_site: str, load_type: str) -> float: ...\n",
    "\n",
    "class STRATEGY(Enum):\n",
    "    STANDARD_DEVIATION = 0\n",
    "    IQR = 1\n",
    "\n",
    "def getUpperLowerLimit(dropoff_site: str, load_type: str, strategy: STRATEGY) -> tuple[float, float]: ...\n",
    "\n",
    "for dropoff_site in dropoff_sites:\n",
    "    for load_type in load_types[dropoff_site]:\n",
    "        load_type_skew = getSkew(dropoff_site, load_type)\n",
    "        if (load_type_skew < -0.5) | (load_type_skew > 0.5):\n",
    "            lower_limit, upper_limit = getUpperLowerLimit(dropoff_site, load_type, strategy=STRATEGY.IQR)\n",
    "            df3 = df3.drop(df3[(df3['dropoff_site'] == dropoff_site) \n",
    "                               & (df3['load_type'] == load_type) \n",
    "                               & ( (df3['load_weight'] < lower_limit ) | ( df3['load_weight'] > upper_limit ) )\n",
    "                              ].index)\n",
    "        else:\n",
    "            print(\"dropoff_site {0} load_type {1} have normal data distribution\".format(dropoff_site, load_type))\n",
    "            pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some dropoff_site and load_type that still have skewed data distribution after the outliers treament:\n",
    "\n",
    "dropoff_site:\n",
    "- **MRF**, with load type:\n",
    "  - [ ] **TIRES**\n",
    "- **TDS LANDFILL**, with load type:\n",
    "  - [ ] **DEAD ANIMAL**\n",
    "  - [ ] **MIXED LITTER**\n",
    "  - [ ] **TIRES**\n",
    "  - [ ] **RECYCLING - SINGLE STREAM**\n",
    "- **ORGANICS BY GOSH**, with load type:\n",
    "  - [ ] **DEAD ANIMAL**\n",
    "- **ON ROUTE HIGH DUMP**, with load type:\n",
    "  - [ ] **ORGANICS**\n",
    "- **PARK BEND**, with load type:\n",
    "  - [ ] **ORGANICS**\n",
    "\n",
    "TODO: ask Instructor on how to handle skewed data distribution after the first outliers treatment failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after dropping outliers in dropoff_site MRF load_type TIRES still have skewed value: 5.68 -> 0.56, outliers: 3%\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type DEAD ANIMAL still have skewed value: 2.25 -> 0.99, outliers: 8%\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type MIXED LITTER still have skewed value: 1.14 -> 0.63, outliers: 2%\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type TIRES still have skewed value: 3.09 -> -0.92, outliers: 20%\n",
      "after dropping outliers in dropoff_site TDS LANDFILL load_type RECYCLING - SINGLE STREAM still have skewed value: 0.99 -> 0.99, outliers: 0%\n",
      "after dropping outliers in dropoff_site ORGANICS BY GOSH load_type DEAD ANIMAL still have skewed value: 3.49 -> 1.47, outliers: 5%\n",
      "after dropping outliers in dropoff_site ON ROUTE HIGH DUMP load_type ORGANICS still have skewed value: -0.88 -> -0.88, outliers: 0%\n",
      "after dropping outliers in dropoff_site PARK BEND load_type ORGANICS still have skewed value: 0.54 -> 0.54, outliers: 0%\n"
     ]
    }
   ],
   "source": [
    "class DEBUG_STRATEGY(Enum):\n",
    "    INFO = 0\n",
    "    VERBOSE = 1\n",
    "\n",
    "DEBUG = DEBUG_STRATEGY.INFO\n",
    "\n",
    "df4 = df3.copy()\n",
    "\n",
    "def getSkew(dropoff_site: str, load_type: str) -> np.float64:\n",
    "    return df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                   & (df4['load_type'] == load_type), 'load_weight'] \\\n",
    "              .skew()\n",
    "\n",
    "class OUTLIER_STRATEGY(Enum):\n",
    "    IQR = 0\n",
    "\n",
    "def getLowerUpperLimit(dropoff_site: str, load_type: str, strategy: OUTLIER_STRATEGY) -> tuple[float, float]:\n",
    "    if strategy == OUTLIER_STRATEGY.IQR:\n",
    "        Q1, Q3 = df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                         & (df4['load_type'] == load_type), 'load_weight'] \\\n",
    "                    .quantile([.25, .75])\n",
    "        IQR = Q3 - Q1\n",
    "        return Q1 - IQR * 1.5, Q3 + IQR * 1.5\n",
    "    else:\n",
    "        raise NotImplementedError(\"currently just handle skewed data distribution\")\n",
    "\n",
    "getSkew('TDS LANDFILL', 'GARBAGE COLLECTIONS')\n",
    "getLowerUpperLimit('TDS LANDFILL', 'GARBAGE COLLECTIONS', OUTLIER_STRATEGY.IQR)\n",
    "\n",
    "for dropoff_site in df4.loc[:,'dropoff_site'].unique():\n",
    "    for load_type in df4.loc[df4['dropoff_site'] == dropoff_site, 'load_type'].unique():\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site=dropoff_site, load_type=load_type)\n",
    "        if np.isnan(dropoff_site_load_type_skew):\n",
    "            \"\"\"\n",
    "            load_type_skew with nan value can happen because: there is not enough data, like only 2 rows.\n",
    "            \"\"\"\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropping dropoff_site {0} load_type {1} because have nan skew value\".format(dropoff_site, load_type))\n",
    "            df4 = df4.drop(df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                                   & (df4['load_type'] == load_type)]\n",
    "                              .index)\n",
    "        elif (dropoff_site_load_type_skew < -0.5) | (dropoff_site_load_type_skew > 0.5):\n",
    "            lower_limit, upper_limit = getLowerUpperLimit(dropoff_site=dropoff_site, load_type=load_type, strategy=OUTLIER_STRATEGY.IQR)\n",
    "            dropoff_site_load_type_rows_length = len(df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                                                             & (df4['load_type'] == load_type)] \\\n",
    "                                                        .index)\n",
    "            index_to_drop = df4.loc[(df4['dropoff_site'] == dropoff_site)\n",
    "                                   & (df4['load_type'] == load_type)\n",
    "                                   & ( (df4['load_weight'] < lower_limit) | (df4['load_weight'] > upper_limit) )] \\\n",
    "                              .index\n",
    "            df4 = df4.drop(index_to_drop)\n",
    "            new_dropoff_site_load_type_skew = df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_type'] == load_type), 'load_weight'].skew()\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropping outliers in dropoff_site {0} load_type {1} because have skewed value: {2:.2f}, outliers: {3:.0%}\".format(dropoff_site, \n",
    "                                                                                                                                         load_type, \n",
    "                                                                                                                                            dropoff_site_load_type_skew, \n",
    "                                                                                                                                         len(index_to_drop) / dropoff_site_load_type_rows_length))\n",
    "            if ((DEBUG == DEBUG_STRATEGY.INFO) | (DEBUG_STRATEGY == DEBUG_STRATEGY.VERBOSE)) & ((new_dropoff_site_load_type_skew < -0.5) | (new_dropoff_site_load_type_skew > 0.5)):\n",
    "                print(\"after dropping outliers in dropoff_site {0} load_type {1} still have skewed value: {2:.2f} -> {3:.2f}, outliers: {4:.0%}\".format(dropoff_site, \n",
    "                                                                                                                                                        load_type, \n",
    "                                                                                                                                                        dropoff_site_load_type_skew, \n",
    "                                                                                                                                                        new_dropoff_site_load_type_skew,\n",
    "                                                                                                                                                        len(index_to_drop) / dropoff_site_load_type_rows_length))\n",
    "        # expected: normal data distribution\n",
    "        else:\n",
    "            if DEBUG == DEBUG_STRATEGY.VERBOSE:\n",
    "                print(\"dropoff_site {0} load_type {1} have skew value {2:.2f}. The decision is not to drop the outliers\".format(dropoff_site, load_type, dropoff_site_load_type_skew))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle NaN rows.\n",
    "\n",
    "Assuming we have done the outliers treatment.\n",
    "\n",
    "~~pseudo code:~~ we only identify 2 combinations, not worth to automate (O )\n",
    "```\n",
    "for dropoff_site in dropoff_sites:\n",
    "    for load_type in dropoff_site['load_type']:\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site, load_type)\n",
    "        if (dropoff_site_load_type_skew < -0.5) | (dropoff_site_load_type_skew > 0.5):\n",
    "            # replace NaN with median\n",
    "        elif:\n",
    "            # repplace NaN with mean\n",
    "```\n",
    "\n",
    "We identified 2 combinations that have NaN rows and have normal data distribution:\n",
    "- [ ] dropoff_site HORNSBY BEND, load type BRUSH\n",
    "- [ ] dropoff_site ORGANICS BY GOSH, load type ORGANICS\n",
    "\n",
    "These combinations are not empty NaN rows. So we will replace it with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_site HORNSBY BEND load_type BRUSH skew 0.2636609436413962\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:57:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>3800.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 08:23:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>4180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:11:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 10:41:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>5680.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2021-03-20</td>\n",
       "      <td>2021-03-20 07:21:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>3180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26005</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:25:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6020.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26006</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:32:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>8180.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26007</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 01:31:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>2940.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26008</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 02:40:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>6680.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26009</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:01:00 UTC</td>\n",
       "      <td>BRUSH</td>\n",
       "      <td>5460.0</td>\n",
       "      <td>HORNSBY BEND</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "160    2021-03-20  2021-03-20 07:57:00 UTC     BRUSH       3800.0   \n",
       "161    2021-03-20  2021-03-20 08:23:00 UTC     BRUSH       4180.0   \n",
       "162    2021-03-20  2021-03-20 07:11:00 UTC     BRUSH       6500.0   \n",
       "163    2021-03-20  2021-03-20 10:41:00 UTC     BRUSH       5680.0   \n",
       "164    2021-03-20  2021-03-20 07:21:00 UTC     BRUSH       3180.0   \n",
       "...           ...                      ...       ...          ...   \n",
       "26005  2021-03-01  2021-03-01 04:25:00 UTC     BRUSH       6020.0   \n",
       "26006  2021-03-01  2021-03-01 11:32:00 UTC     BRUSH       8180.0   \n",
       "26007  2021-03-01  2021-03-01 01:31:00 UTC     BRUSH       2940.0   \n",
       "26008  2021-03-01  2021-03-01 02:40:00 UTC     BRUSH       6680.0   \n",
       "26009  2021-03-01  2021-03-01 04:01:00 UTC     BRUSH       5460.0   \n",
       "\n",
       "       dropoff_site  \n",
       "160    HORNSBY BEND  \n",
       "161    HORNSBY BEND  \n",
       "162    HORNSBY BEND  \n",
       "163    HORNSBY BEND  \n",
       "164    HORNSBY BEND  \n",
       "...             ...  \n",
       "26005  HORNSBY BEND  \n",
       "26006  HORNSBY BEND  \n",
       "26007  HORNSBY BEND  \n",
       "26008  HORNSBY BEND  \n",
       "26009  HORNSBY BEND  \n",
       "\n",
       "[1515 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropoff_site ORGANICS BY GOSH load_type ORGANICS skew 0.07768898474656169\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>load_time</th>\n",
       "      <th>load_type</th>\n",
       "      <th>load_weight</th>\n",
       "      <th>dropoff_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>2021-02-21 10:41:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>2021-03-14 01:37:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21700.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2021-03-21</td>\n",
       "      <td>2021-03-21 07:56:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>7120.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>2021-02-21</td>\n",
       "      <td>2021-02-21 11:07:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>2021-03-14</td>\n",
       "      <td>2021-03-14 03:04:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>20460.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26151</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:19:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>18580.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26152</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 11:26:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>12100.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26153</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 04:27:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>10900.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-01 05:55:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>21800.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26155</th>\n",
       "      <td>2021-03-01</td>\n",
       "      <td>2021-03-02 01:10:00 UTC</td>\n",
       "      <td>ORGANICS</td>\n",
       "      <td>5640.0</td>\n",
       "      <td>ORGANICS BY GOSH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      report_date                load_time load_type  load_weight  \\\n",
       "775    2021-02-21  2021-02-21 10:41:00 UTC  ORGANICS       2480.0   \n",
       "776    2021-03-14  2021-03-14 01:37:00 UTC  ORGANICS      21700.0   \n",
       "777    2021-03-21  2021-03-21 07:56:00 UTC  ORGANICS       7120.0   \n",
       "778    2021-02-21  2021-02-21 11:07:00 UTC  ORGANICS       5560.0   \n",
       "779    2021-03-14  2021-03-14 03:04:00 UTC  ORGANICS      20460.0   \n",
       "...           ...                      ...       ...          ...   \n",
       "26151  2021-03-01  2021-03-01 11:19:00 UTC  ORGANICS      18580.0   \n",
       "26152  2021-03-01  2021-03-01 11:26:00 UTC  ORGANICS      12100.0   \n",
       "26153  2021-03-01  2021-03-01 04:27:00 UTC  ORGANICS      10900.0   \n",
       "26154  2021-03-01  2021-03-01 05:55:00 UTC  ORGANICS      21800.0   \n",
       "26155  2021-03-01  2021-03-02 01:10:00 UTC  ORGANICS       5640.0   \n",
       "\n",
       "           dropoff_site  \n",
       "775    ORGANICS BY GOSH  \n",
       "776    ORGANICS BY GOSH  \n",
       "777    ORGANICS BY GOSH  \n",
       "778    ORGANICS BY GOSH  \n",
       "779    ORGANICS BY GOSH  \n",
       "...                 ...  \n",
       "26151  ORGANICS BY GOSH  \n",
       "26152  ORGANICS BY GOSH  \n",
       "26153  ORGANICS BY GOSH  \n",
       "26154  ORGANICS BY GOSH  \n",
       "26155  ORGANICS BY GOSH  \n",
       "\n",
       "[5728 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dropoff_site in df4.loc[df4['load_weight'].isna(),'dropoff_site'].unique():\n",
    "    for load_type in df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_weight'].isna()), 'load_type'].unique():\n",
    "        dropoff_site_load_type_skew = getSkew(dropoff_site=dropoff_site, load_type=load_type)\n",
    "        print(f\"dropoff_site {dropoff_site} load_type {load_type} skew {dropoff_site_load_type_skew}\")\n",
    "        display(df4.loc[(df4['dropoff_site'] == dropoff_site) & (df4['load_type'] == load_type)])\n",
    "\n",
    "df5 = df4.copy()\n",
    "\n",
    "df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "        & (df5['load_type'] == 'BRUSH') \n",
    "        & (df5['load_weight'].isna()), 'load_weight'] = df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "                                                                & (df5['load_type'] == 'BRUSH'), 'load_weight'] \\\n",
    "                                                            .mean()\n",
    "\n",
    "df5.loc[(df5['dropoff_site'] == 'ORGANICS BY GOSH') \n",
    "        & (df5['load_type'] == 'ORGANICS') \n",
    "        & (df5['load_weight'].isna()), 'load_weight'] = df5.loc[(df5['dropoff_site'] == 'HORNSBY BEND') \n",
    "                                                                & (df5['load_type'] == 'BRUSH'), 'load_weight'] \\\n",
    "                                                            .mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No more NaN rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25066 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   report_date   25066 non-null  object \n",
      " 1   load_time     25066 non-null  object \n",
      " 2   load_type     25066 non-null  object \n",
      " 3   load_weight   25066 non-null  float64\n",
      " 4   dropoff_site  25066 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change column `report_date` and `load_time` dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['report_date'] = pd.to_datetime(df5['report_date'])\n",
    "df5['load_time'] = pd.to_datetime(df5['load_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 25066 entries, 0 to 26156\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype              \n",
      "---  ------        --------------  -----              \n",
      " 0   report_date   25066 non-null  datetime64[ns]     \n",
      " 1   load_time     25066 non-null  datetime64[ns, UTC]\n",
      " 2   load_type     25066 non-null  object             \n",
      " 3   load_weight   25066 non-null  float64            \n",
      " 4   dropoff_site  25066 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df5.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TIRES', 'RECYCLING - SINGLE STREAM', 'BRUSH', 'YARD TRIMMING',\n",
       "       'BULK', 'ORGANICS', 'DEAD ANIMAL', 'GARBAGE COLLECTIONS',\n",
       "       'MIXED LITTER', 'SWEEPING', 'LITTER', 'RECYCLED METAL'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.loc[:, 'load_type'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Off Site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MRF', 'TDS - MRF', 'HORNSBY BEND', 'TDS LANDFILL',\n",
       "       'ORGANICS BY GOSH', 'BALCONES RECYCLING', 'ON ROUTE HIGH DUMP',\n",
       "       'AUSTIN IRON AND METAL', 'PARK BEND', 'GREAT NORTHERN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5.loc[:,'dropoff_site'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central Tendency\n",
    "\n",
    "There is no one `mode` for rows that is grouped by `dropoff_site`. This is because the column `load_weight` values are mostly unique. If we do `agg([..., pd.Series.mode])`, it will throw error. So, we have to be a bit creative.\n",
    "\n",
    "The insights for data analyst:\n",
    "1. drop off site **GREAT NORTHERN** and other drop off site that experience increase in average load weight. This happens because we remove some load type due to:\n",
    "   1. specific load type only have 2 rows or less. Consequently, we can't calculate the skew value. (+ increase mean)\n",
    "   2. specific load type with more than 2 rows but the entire rows value are NaN. (+ increase mean)\n",
    "   3. specific load type have skewed data distribution. Consequently, we remove the outliers with IQR strategy. (- decrease mean)\n",
    "\n",
    "The insights for management:\n",
    "1. drop off site **GREAT NORTHERN** have the highest average load weight, 19% higher than the next highest average load weight's dropoff site. After we do outlier handling, the difference increase to 40%.\n",
    "2. drop off site **AUSTIN IRON AND METAL** have the lowest average load weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"6\" halign=\"left\">load_weight</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>df2 mean</th>\n",
       "      <th>df5 mean</th>\n",
       "      <th>df2 median</th>\n",
       "      <th>df5 median</th>\n",
       "      <th>df2 mode</th>\n",
       "      <th>df5 mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUSTIN IRON AND METAL</th>\n",
       "      <td>451.20</td>\n",
       "      <td>426.25</td>\n",
       "      <td>400.00</td>\n",
       "      <td>395.00</td>\n",
       "      <td>found 3 different modes</td>\n",
       "      <td>found 3 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUSTIN WOOD RECYCLING</th>\n",
       "      <td>4,050.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4,050.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>found 2 different modes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES RECYCLING</th>\n",
       "      <td>9,464.65</td>\n",
       "      <td>9,464.65</td>\n",
       "      <td>9,840.00</td>\n",
       "      <td>9,840.00</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>found 1 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES WOODS</th>\n",
       "      <td>8,460.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8,460.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREAT NORTHERN</th>\n",
       "      <td>19,153.33</td>\n",
       "      <td>21,244.00</td>\n",
       "      <td>21,110.00</td>\n",
       "      <td>21,320.00</td>\n",
       "      <td>found 6 different modes</td>\n",
       "      <td>found 5 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORNSBY BEND</th>\n",
       "      <td>6,628.64</td>\n",
       "      <td>6,624.97</td>\n",
       "      <td>6,390.00</td>\n",
       "      <td>6,380.00</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>found 1 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRF</th>\n",
       "      <td>1,799.98</td>\n",
       "      <td>1,426.48</td>\n",
       "      <td>1,360.00</td>\n",
       "      <td>1,330.00</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>found 1 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON ROUTE HIGH DUMP</th>\n",
       "      <td>12,525.71</td>\n",
       "      <td>12,525.71</td>\n",
       "      <td>14,940.00</td>\n",
       "      <td>14,940.00</td>\n",
       "      <td>found 7 different modes</td>\n",
       "      <td>found 7 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS BY GOSH</th>\n",
       "      <td>11,818.48</td>\n",
       "      <td>11,806.21</td>\n",
       "      <td>11,920.00</td>\n",
       "      <td>11,900.00</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>found 1 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK BEND</th>\n",
       "      <td>13,385.00</td>\n",
       "      <td>13,385.00</td>\n",
       "      <td>12,330.00</td>\n",
       "      <td>12,330.00</td>\n",
       "      <td>found 4 different modes</td>\n",
       "      <td>found 4 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STEINER LANDFILL</th>\n",
       "      <td>780.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>780.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS - MRF</th>\n",
       "      <td>9,872.55</td>\n",
       "      <td>9,875.78</td>\n",
       "      <td>10,330.00</td>\n",
       "      <td>10,340.00</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>found 1 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS LANDFILL</th>\n",
       "      <td>15,169.41</td>\n",
       "      <td>15,118.93</td>\n",
       "      <td>14,920.00</td>\n",
       "      <td>14,940.00</td>\n",
       "      <td>found 3 different modes</td>\n",
       "      <td>found 3 different modes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WESTFIELD</th>\n",
       "      <td>16,020.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16,020.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>found 1 different modes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      load_weight                                  \\\n",
       "                         df2 mean  df5 mean df2 median df5 median   \n",
       "dropoff_site                                                        \n",
       "AUSTIN IRON AND METAL      451.20    426.25     400.00     395.00   \n",
       "AUSTIN WOOD RECYCLING    4,050.00       NaN   4,050.00        NaN   \n",
       "BALCONES RECYCLING       9,464.65  9,464.65   9,840.00   9,840.00   \n",
       "BALCONES WOODS           8,460.00       NaN   8,460.00        NaN   \n",
       "GREAT NORTHERN          19,153.33 21,244.00  21,110.00  21,320.00   \n",
       "HORNSBY BEND             6,628.64  6,624.97   6,390.00   6,380.00   \n",
       "MRF                      1,799.98  1,426.48   1,360.00   1,330.00   \n",
       "ON ROUTE HIGH DUMP      12,525.71 12,525.71  14,940.00  14,940.00   \n",
       "ORGANICS BY GOSH        11,818.48 11,806.21  11,920.00  11,900.00   \n",
       "PARK BEND               13,385.00 13,385.00  12,330.00  12,330.00   \n",
       "STEINER LANDFILL           780.00       NaN     780.00        NaN   \n",
       "TDS - MRF                9,872.55  9,875.78  10,330.00  10,340.00   \n",
       "TDS LANDFILL            15,169.41 15,118.93  14,920.00  14,940.00   \n",
       "WESTFIELD               16,020.00       NaN  16,020.00        NaN   \n",
       "\n",
       "                                                                         \n",
       "                                      df2 mode                 df5 mode  \n",
       "dropoff_site                                                             \n",
       "AUSTIN IRON AND METAL  found 3 different modes  found 3 different modes  \n",
       "AUSTIN WOOD RECYCLING  found 2 different modes                      NaN  \n",
       "BALCONES RECYCLING     found 1 different modes  found 1 different modes  \n",
       "BALCONES WOODS         found 1 different modes                      NaN  \n",
       "GREAT NORTHERN         found 6 different modes  found 5 different modes  \n",
       "HORNSBY BEND           found 1 different modes  found 1 different modes  \n",
       "MRF                    found 1 different modes  found 1 different modes  \n",
       "ON ROUTE HIGH DUMP     found 7 different modes  found 7 different modes  \n",
       "ORGANICS BY GOSH       found 1 different modes  found 1 different modes  \n",
       "PARK BEND              found 4 different modes  found 4 different modes  \n",
       "STEINER LANDFILL       found 1 different modes                      NaN  \n",
       "TDS - MRF              found 1 different modes  found 1 different modes  \n",
       "TDS LANDFILL           found 3 different modes  found 3 different modes  \n",
       "WESTFIELD              found 1 different modes                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# force pandas to suppress the scientific notation.\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "df2_central_tendency = df2.loc[:,['dropoff_site', 'load_weight']].groupby(['dropoff_site']).agg([(\"df2 mean\", \"mean\"), \n",
    "                                                                                                 (\"df2 median\", \"median\"), \n",
    "                                                                                                 (\"df2 mode\", lambda x: \"found {0} different modes\".format(len(x.mode().tolist())))])\n",
    "\n",
    "df5_central_tendency = df5.loc[:,['dropoff_site', 'load_weight']].groupby(['dropoff_site']).agg([(\"df5 mean\",\"mean\"), \n",
    "                                                                                                 (\"df5 median\",\"median\"), \n",
    "                                                                                                 (\"df5 mode\", lambda x: \"found {0} different modes\".format(len(x.mode().tolist())))])\n",
    "\n",
    "df2_df5_central_tendency = pd.concat([df2_central_tendency, df5_central_tendency], axis='columns')\n",
    "\n",
    "# sort the columns\n",
    "df2_df5_central_tendency_columns = df2_df5_central_tendency.columns.tolist()\n",
    "df2_df5_central_tendency_columns = df2_df5_central_tendency_columns[0:1] \\\n",
    "                                   + df2_df5_central_tendency_columns[3:4] \\\n",
    "                                   + df2_df5_central_tendency_columns[1:2] \\\n",
    "                                   + df2_df5_central_tendency_columns[4:5] \\\n",
    "                                   + df2_df5_central_tendency_columns[2:3] \\\n",
    "                                   + df2_df5_central_tendency_columns[5:6]\n",
    "df2_df5_central_tendency = df2_df5_central_tendency[df2_df5_central_tendency_columns]\n",
    "\n",
    "display(df2_df5_central_tendency)\n",
    "\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variance\n",
    "\n",
    "In this part, Jason chose the drop off site **AUSTIN IRON AND METALn** to analyze further. This is because it has the lowest variance (of groupby drop off site). It also have the least amount of load types. Hopefully, we can predict accurately the load weight for load type **RECYCLED METAL** on July 10, 2021.\n",
    "\n",
    "The insights to management:\n",
    "1. High variance means for each delivery, the load weight have high difference. For example, yesterday drop off site **AUSTIN IRON AND METAL** collected 1.500 recycled metal. Today, they collected 10.000 recycled metal. This makes predicting the future harder.\n",
    "2. From standard deviation, we can expect the minimum and maximum load weight per delivery. For example, if the average load weight of recycled metal is 50. The standard deviation is 5. Then we can expect today's load weight to be around `50 +- 5` (or between 45 to 55 recycled metal)\n",
    "3. The range is just a historical data. It tells us the minimum and maximum load weight for a specific drop off site and load type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_site</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUSTIN IRON AND METAL</th>\n",
       "      <td>32,585.64</td>\n",
       "      <td>180.51</td>\n",
       "      <td>140.00 - 830.00</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES RECYCLING</th>\n",
       "      <td>14,916,926.03</td>\n",
       "      <td>3,862.24</td>\n",
       "      <td>140.00 - 25,780.00</td>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREAT NORTHERN</th>\n",
       "      <td>7,634,080.00</td>\n",
       "      <td>2,762.98</td>\n",
       "      <td>17,160.00 - 24,880.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HORNSBY BEND</th>\n",
       "      <td>10,474,661.65</td>\n",
       "      <td>3,236.46</td>\n",
       "      <td>60.00 - 20,460.00</td>\n",
       "      <td>1652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRF</th>\n",
       "      <td>756,077.76</td>\n",
       "      <td>869.53</td>\n",
       "      <td>40.00 - 4,120.00</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON ROUTE HIGH DUMP</th>\n",
       "      <td>25,274,361.90</td>\n",
       "      <td>5,027.36</td>\n",
       "      <td>4,060.00 - 18,460.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS BY GOSH</th>\n",
       "      <td>25,718,646.21</td>\n",
       "      <td>5,071.36</td>\n",
       "      <td>20.00 - 29,660.00</td>\n",
       "      <td>5751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK BEND</th>\n",
       "      <td>32,736,366.67</td>\n",
       "      <td>5,721.57</td>\n",
       "      <td>8,480.00 - 20,400.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS - MRF</th>\n",
       "      <td>16,640,346.15</td>\n",
       "      <td>4,079.26</td>\n",
       "      <td>40.00 - 29,940.00</td>\n",
       "      <td>2945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDS LANDFILL</th>\n",
       "      <td>61,507,930.39</td>\n",
       "      <td>7,842.70</td>\n",
       "      <td>0.00 - 35,900.00</td>\n",
       "      <td>10657</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                var      std                  range  count\n",
       "dropoff_site                                                              \n",
       "AUSTIN IRON AND METAL     32,585.64   180.51        140.00 - 830.00     48\n",
       "BALCONES RECYCLING    14,916,926.03 3,862.24     140.00 - 25,780.00   3837\n",
       "GREAT NORTHERN         7,634,080.00 2,762.98  17,160.00 - 24,880.00      5\n",
       "HORNSBY BEND          10,474,661.65 3,236.46      60.00 - 20,460.00   1652\n",
       "MRF                      756,077.76   869.53       40.00 - 4,120.00    160\n",
       "ON ROUTE HIGH DUMP    25,274,361.90 5,027.36   4,060.00 - 18,460.00      7\n",
       "ORGANICS BY GOSH      25,718,646.21 5,071.36      20.00 - 29,660.00   5751\n",
       "PARK BEND             32,736,366.67 5,721.57   8,480.00 - 20,400.00      4\n",
       "TDS - MRF             16,640,346.15 4,079.26      40.00 - 29,940.00   2945\n",
       "TDS LANDFILL          61,507,930.39 7,842.70       0.00 - 35,900.00  10657"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>std</th>\n",
       "      <th>range</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dropoff_site</th>\n",
       "      <th>load_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUSTIN IRON AND METAL</th>\n",
       "      <th>RECYCLED METAL</th>\n",
       "      <td>32,585.64</td>\n",
       "      <td>180.51</td>\n",
       "      <td>140.00 - 830.00</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BALCONES RECYCLING</th>\n",
       "      <th>RECYCLING - SINGLE STREAM</th>\n",
       "      <td>14,916,926.03</td>\n",
       "      <td>3,862.24</td>\n",
       "      <td>140.00 - 25,780.00</td>\n",
       "      <td>3837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GREAT NORTHERN</th>\n",
       "      <th>GARBAGE COLLECTIONS</th>\n",
       "      <td>7,634,080.00</td>\n",
       "      <td>2,762.98</td>\n",
       "      <td>17,160.00 - 24,880.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">HORNSBY BEND</th>\n",
       "      <th>BRUSH</th>\n",
       "      <td>7,727,648.71</td>\n",
       "      <td>2,779.86</td>\n",
       "      <td>60.00 - 19,660.00</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YARD TRIMMING</th>\n",
       "      <td>20,280,793.43</td>\n",
       "      <td>4,503.42</td>\n",
       "      <td>1,220.00 - 20,460.00</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRF</th>\n",
       "      <th>TIRES</th>\n",
       "      <td>756,077.76</td>\n",
       "      <td>869.53</td>\n",
       "      <td>40.00 - 4,120.00</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ON ROUTE HIGH DUMP</th>\n",
       "      <th>ORGANICS</th>\n",
       "      <td>25,274,361.90</td>\n",
       "      <td>5,027.36</td>\n",
       "      <td>4,060.00 - 18,460.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ORGANICS BY GOSH</th>\n",
       "      <th>DEAD ANIMAL</th>\n",
       "      <td>21,371.24</td>\n",
       "      <td>146.19</td>\n",
       "      <td>20.00 - 540.00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS</th>\n",
       "      <td>25,363,827.47</td>\n",
       "      <td>5,036.25</td>\n",
       "      <td>20.00 - 29,660.00</td>\n",
       "      <td>5728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECYCLED METAL</th>\n",
       "      <td>41,652,720.00</td>\n",
       "      <td>6,453.89</td>\n",
       "      <td>5,160.00 - 20,760.00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PARK BEND</th>\n",
       "      <th>ORGANICS</th>\n",
       "      <td>32,736,366.67</td>\n",
       "      <td>5,721.57</td>\n",
       "      <td>8,480.00 - 20,400.00</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">TDS - MRF</th>\n",
       "      <th>GARBAGE COLLECTIONS</th>\n",
       "      <td>53,283,121.16</td>\n",
       "      <td>7,299.53</td>\n",
       "      <td>3,400.00 - 29,940.00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECYCLING - SINGLE STREAM</th>\n",
       "      <td>15,844,366.84</td>\n",
       "      <td>3,980.50</td>\n",
       "      <td>40.00 - 27,060.00</td>\n",
       "      <td>2917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">TDS LANDFILL</th>\n",
       "      <th>BULK</th>\n",
       "      <td>15,220,546.84</td>\n",
       "      <td>3,901.35</td>\n",
       "      <td>20.00 - 28,000.00</td>\n",
       "      <td>1590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEAD ANIMAL</th>\n",
       "      <td>7,892.89</td>\n",
       "      <td>88.84</td>\n",
       "      <td>20.00 - 380.00</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GARBAGE COLLECTIONS</th>\n",
       "      <td>48,916,474.77</td>\n",
       "      <td>6,994.03</td>\n",
       "      <td>0.12 - 35,900.00</td>\n",
       "      <td>8197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LITTER</th>\n",
       "      <td>1,947,616.73</td>\n",
       "      <td>1,395.57</td>\n",
       "      <td>600.00 - 6,340.00</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIXED LITTER</th>\n",
       "      <td>2,082,024.42</td>\n",
       "      <td>1,442.92</td>\n",
       "      <td>0.00 - 7,000.00</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ORGANICS</th>\n",
       "      <td>5,564.71</td>\n",
       "      <td>74.60</td>\n",
       "      <td>20.00 - 220.00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RECYCLING - SINGLE STREAM</th>\n",
       "      <td>6,254,800.00</td>\n",
       "      <td>2,500.96</td>\n",
       "      <td>420.00 - 5,320.00</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SWEEPING</th>\n",
       "      <td>20,577,778.75</td>\n",
       "      <td>4,536.27</td>\n",
       "      <td>760.00 - 22,760.00</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIRES</th>\n",
       "      <td>160,428.57</td>\n",
       "      <td>400.54</td>\n",
       "      <td>1,300.00 - 2,380.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          var      std  \\\n",
       "dropoff_site          load_type                                          \n",
       "AUSTIN IRON AND METAL RECYCLED METAL                32,585.64   180.51   \n",
       "BALCONES RECYCLING    RECYCLING - SINGLE STREAM 14,916,926.03 3,862.24   \n",
       "GREAT NORTHERN        GARBAGE COLLECTIONS        7,634,080.00 2,762.98   \n",
       "HORNSBY BEND          BRUSH                      7,727,648.71 2,779.86   \n",
       "                      YARD TRIMMING             20,280,793.43 4,503.42   \n",
       "MRF                   TIRES                        756,077.76   869.53   \n",
       "ON ROUTE HIGH DUMP    ORGANICS                  25,274,361.90 5,027.36   \n",
       "ORGANICS BY GOSH      DEAD ANIMAL                   21,371.24   146.19   \n",
       "                      ORGANICS                  25,363,827.47 5,036.25   \n",
       "                      RECYCLED METAL            41,652,720.00 6,453.89   \n",
       "PARK BEND             ORGANICS                  32,736,366.67 5,721.57   \n",
       "TDS - MRF             GARBAGE COLLECTIONS       53,283,121.16 7,299.53   \n",
       "                      RECYCLING - SINGLE STREAM 15,844,366.84 3,980.50   \n",
       "TDS LANDFILL          BULK                      15,220,546.84 3,901.35   \n",
       "                      DEAD ANIMAL                    7,892.89    88.84   \n",
       "                      GARBAGE COLLECTIONS       48,916,474.77 6,994.03   \n",
       "                      LITTER                     1,947,616.73 1,395.57   \n",
       "                      MIXED LITTER               2,082,024.42 1,442.92   \n",
       "                      ORGANICS                       5,564.71    74.60   \n",
       "                      RECYCLING - SINGLE STREAM  6,254,800.00 2,500.96   \n",
       "                      SWEEPING                  20,577,778.75 4,536.27   \n",
       "                      TIRES                        160,428.57   400.54   \n",
       "\n",
       "                                                                 range  count  \n",
       "dropoff_site          load_type                                                \n",
       "AUSTIN IRON AND METAL RECYCLED METAL                   140.00 - 830.00     48  \n",
       "BALCONES RECYCLING    RECYCLING - SINGLE STREAM     140.00 - 25,780.00   3837  \n",
       "GREAT NORTHERN        GARBAGE COLLECTIONS        17,160.00 - 24,880.00      5  \n",
       "HORNSBY BEND          BRUSH                          60.00 - 19,660.00   1515  \n",
       "                      YARD TRIMMING               1,220.00 - 20,460.00    137  \n",
       "MRF                   TIRES                           40.00 - 4,120.00    160  \n",
       "ON ROUTE HIGH DUMP    ORGANICS                    4,060.00 - 18,460.00      7  \n",
       "ORGANICS BY GOSH      DEAD ANIMAL                       20.00 - 540.00     18  \n",
       "                      ORGANICS                       20.00 - 29,660.00   5728  \n",
       "                      RECYCLED METAL              5,160.00 - 20,760.00      5  \n",
       "PARK BEND             ORGANICS                    8,480.00 - 20,400.00      4  \n",
       "TDS - MRF             GARBAGE COLLECTIONS         3,400.00 - 29,940.00     28  \n",
       "                      RECYCLING - SINGLE STREAM      40.00 - 27,060.00   2917  \n",
       "TDS LANDFILL          BULK                           20.00 - 28,000.00   1590  \n",
       "                      DEAD ANIMAL                       20.00 - 380.00    121  \n",
       "                      GARBAGE COLLECTIONS             0.12 - 35,900.00   8197  \n",
       "                      LITTER                         600.00 - 6,340.00     39  \n",
       "                      MIXED LITTER                     0.00 - 7,000.00    321  \n",
       "                      ORGANICS                          20.00 - 220.00     18  \n",
       "                      RECYCLING - SINGLE STREAM      420.00 - 5,320.00      3  \n",
       "                      SWEEPING                      760.00 - 22,760.00    360  \n",
       "                      TIRES                        1,300.00 - 2,380.00      8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# force pandas to suppress the scientific notation.\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "display(df5.groupby(['dropoff_site'])['load_weight'].agg(['var', \n",
    "                                                          'std',\n",
    "                                                          ('range', lambda x: \"{0:,.2f} - {1:,.2f}\".format(x.min(), x.max())),\n",
    "                                                          'count']))\n",
    "\n",
    "display(df5.groupby(['dropoff_site', 'load_type'])['load_weight'].agg(['var', \n",
    "                                                                       'std',\n",
    "                                                                       ('range', lambda x: \"{0:,.2f} - {1:,.2f}\".format(x.min(), x.max())),\n",
    "                                                                       'count']))\n",
    "\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Drop Off Site\n",
    "\n",
    "The sample data that we are going to use is drop off site AUSTIN IRON AND METAL with load type RECYCLED METAL.\n",
    "\n",
    "H0:  <= 356\n",
    "\n",
    "H1:  > 356\n",
    "\n",
    "The usual confidence interval is 95%. So we will use it. Therefore, we will reject the null hypothesis if the p-value is less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drop off site AUSTIN IRON AND METAL load type RECYCLED METAL estimated standard deviation population: 178.62466468361342\n"
     ]
    }
   ],
   "source": [
    "df5_AUSTIN_IRON_AND_METAL = df5.loc[df5['dropoff_site'] == 'AUSTIN IRON AND METAL']\n",
    "\n",
    "print(\"drop off site AUSTIN IRON AND METAL load type RECYCLED METAL estimated standard deviation population:\", df5_AUSTIN_IRON_AND_METAL.loc[:,'load_weight'].std(ddof=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our p-value is less than `0.05`, so we reject the null hypothesis and we can conclude that, the average load weight of drop off site is more than 356 recycled metal per delivery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.696210719450297, 0.004851352331943044)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic, pvalue = stats.ttest_1samp(a=df5_AUSTIN_IRON_AND_METAL.loc[:,'load_weight'], \n",
    "                                      popmean=356,\n",
    "                                      alternative=\"greater\")\n",
    "statistic, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The average load time between delivery is 3 days 22 hours. Therefore, if drop off site AUSTIN IRON AND METAL were to be closed off and if the new drop off site can process `356 + 3 * 178.6` recycled materials `(from estimated mean population + 3 * estimated standard deviation population)` recycled metal every 3 days, we can safely assume the new drop off site with capacity of `891.8` reycycled metal every 3 days can operate without issue 99.73% of the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('3 days 21:57:05.106382978')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df6 = df5.sort_values(['load_time']).copy()\n",
    "df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL','previous_load_time'] = df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL','load_time'].shift()\n",
    "df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL','between_load_time'] = df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL','load_time'] - df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL','previous_load_time']\n",
    "df6.loc[df6['dropoff_site'] == 'AUSTIN IRON AND METAL', 'between_load_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecasting July 10th, 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whari ini: 120,340.00, wbesok: 112,429.57\n"
     ]
    }
   ],
   "source": [
    "# force pandas to supress the scientific notation\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# groupby automatically sort the column, so we do not need to call `sort_values('report_date')`\n",
    "# w = f(t)\n",
    "# dw\n",
    "# -- = f'(t)\n",
    "# dt\n",
    "y = df6.loc[:,['report_date', 'load_weight']].groupby(['report_date']).sum()\n",
    "\n",
    "# we calculate the cumulative load weight because\n",
    "# 1. drop off site is a depot to collect waste, not to send it somewhere else.\n",
    "# 2. no drop off site have ever write negative load_weight / \n",
    "#    indicating they send the waste out from the drop off site.\n",
    "# 3. if we imagine `w` to have a function e.g `f(t)`, we don't know what's on the right side of the equation,\n",
    "#    but let's say we do, for example f(2) should be = w on time 1 + w on time 2.\n",
    "#    therefore, the derivative of f'(t) or v should be cumulative as well.\n",
    "y['cumulative_load_weight'] = y['load_weight'].cumsum()\n",
    "\n",
    "dx = [0]\n",
    "\n",
    "for i in range(1, len(y.reset_index().index)):\n",
    "    dx.append(dx[i-1] + i)\n",
    "\n",
    "v = np.diff(y.loc[:,'load_weight']) / np.diff(dx)\n",
    "\n",
    "w_besok = y.iloc[-1]['load_weight'] + v[-1] * 1\n",
    "print(\"whari ini: {0:,.2f}, wbesok: {1:,.2f}\".format(y.iloc[-1]['load_weight'], w_besok))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "\n",
    "Answering the questions:\n",
    "1. We use 2 strategy to handle outliers.\n",
    "   1. If the data distribution is normal, we can safely use the `sample mean +- 3 * sample standard deviation` as the upper and lower limit. Data outside the upper and lower limit will be considered as outliers. However, because we do automatic strategy and so there is no time to determine whether the outliers are natural variations or not, we decided not to drop the outliers if the data distribution is normal.\n",
    "   2. If the data distribution is skewed, we will use Interquartile Range (IQR) to detect outliers. In this case, lower limit `Q1 - IQR * 1.5` and upper limit `Q3 + IQR * 1.5`. Any data outside the lower and uppepr limit will be deleted.\n",
    "   3. The reason we use IQR for data that have skewed distribution is because of the very nature of `mean` formula which is `sum of the data divided by length of the data`. For example, if we have a data of `[1,1,1,100]`, at a glance we can determine that 100 is an outlier. If we use the `sample mean +- 3 * sample standard deviation` strategy, the result is that no data is detected as outliers since the lower limit is `-122.75` and upper limit is `174.5`. This where IQR comes in handy, it is not as affected by outliers as the previous strategy. With IQR, the lower limit is `-36.125` and upper limit is `62.875`. The result is data without outlier `[1,1,1]`\n",
    "\n",
    "2. I will explain with example, 5% confidence interval, the usual number we use, if we do reject H0, we can confidently says that there is only 5% chance of the alternative hypothesis is failing, while 95% of the time the hypothesis alternative is true.\n",
    "\n",
    "3. I use hypothesis testing one sample right sided because I want to confidently know the minimum population mean, from there I can estimate the minimum capacity of a drop off site to be able to work without issue 99.73% of the time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "\n",
    "Answering questions:\n",
    "1. For this case, we use the numeric method. This is easier because we can derivate from `load_weight` to `load_weight speed` of each day just by calculating the difference between `load_weight` index N+1 substracted by `load_weight` index N.\n",
    "2. function `numpy.diff()` is actually calculating the difference between value N+1 and value N. This is because we are using the numeric method. Therefore, we need `mathemtical function` to calculate the derivative.\n",
    "3. The estimated total load weight on July 10th, 2021 is 112,429.57"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions, Assumptions, Overall Analysis\n",
    "\n",
    "According to the sample data after we clean up the outliers, these are the insight for the management about drop off site AUSTIN IRON AND METAL:\n",
    "1. The average load time between delivery is 3 days and 22 hours. This means, for every delivery, the drop off site have exactly 3 days and 22 hours to process the recycled metal before the next delivery coming in.\n",
    "2. The hypothesis testing one sample one sided concludes that the estimated population mean is larger than 356. Therefore, if we close off AUSTIN IRON AND METAL and make a new drop off site. We can safely design a drop off site with capacity of `891.8` recycled metal every 3 days that will operate without issue 99,73% of the time.\n",
    "\n",
    "Other insight for the management is:\n",
    "1. The estimated total load weight on July 10th, 2021 is 112,429.57. This means if we combine load weight collected of every drop off sites in Austin, the estimated total load weight will be 112,429.57 tons (the load weight measurement is taken from [Austin, Texas government website](https://data.austintexas.gov/Utilities-and-City-Services/Waste-Collection-Diversion-Report-daily-/mbnu-4wq9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
